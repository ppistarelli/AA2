![feceia1](https://github.com/martinperrone/TP_aprendizaje_automatico/assets/109038969/1e6bd2ee-df8f-4f79-93fd-6d11caba36da)
![Banner_AA2](https://github.com/martinperrone/AA2_tp1/assets/109038969/10b37f6f-dea3-416a-b707-db77644b5186)

# Tecnicatura Universitaria en Inteligencia Artificial (TUIA)
<br><br>
## Trabajo Práctico 2


Integrantes:
* Pablo Pistarelli
* Max Eder
* Martín L. Perrone

<br><br>



<table>
  
  <tr>
    <th>Ejercicio </th>
    <th>Fuente de datos</th>
    <th>Descripción</th>
    <th>Recursos</th>
  </tr>
  <tr>
    <td><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</b></td>
    <td>Dataset: "spoken_digit" de https://www.tensorflow.org/</td>
    <td>El dataset proporcionado incluye un total de 2500 clips de audio correspondientes a 5 locutores distintos, 50 clips por dígito por locutor. Se solicita entrenar dos modelos de distintas arquitecturas y comparar los resultados:

- Modelo convolucional sobre los espectrogramas de los clips.
- Modelo recurrente sobre los espectrogramas de los clips. </td>
    <td>tp2_aa2_ej1.ipynb</td>
  </tr>
  <tr>
    <td><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2</b></td>
    <td>Dataset: "ag_news_subset" de https://www.tensorflow.org/</td>
    <td>El dataset proporcionado incluye 120000 artículos correspondientes a 4 categorías distintas. En este caso, la categoría no es relevante, sólo utilizaremos el dataset como un cuerpo de texto para entrenar un modelo recurrente de generación de texto. Se solicita experimentar con los siguientes tipos de modelos:
- Caracter a caracter: entrenar un modelo de generación de texto a nivel de caracteres como el correspondiente al Lab10 mencionado anteriormente.
- Palabra a palabra: entrenar un modelo de generación de texto a nivel de palabras, adecuando los procesos de entrenamiento e inferencia según sea necesario.
 </td>
    <td>tp2_aa2_ej2_a.ipynb
    tp2_aa2_ej2_b.ipynb</td>
  </tr>

  </tr>
</table>
<br><br>
